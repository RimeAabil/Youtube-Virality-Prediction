# -*- coding: utf-8 -*-
"""YOUTUBE_EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EAK5wwyZNrF_rd05x_jVV9AxI2xGz_B8
"""

import logging
from typing import Dict, List, Any, Tuple, Optional
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from wordcloud import WordCloud
import plotly.express as px
import plotly.graph_objects as go

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)
plt.style.use('seaborn-v0_8-whitegrid')
sns.set(font_scale=1.2)

def plot_video_statistics(df, top_n = 20):

    # Ensure we have the right columns
    required_cols = ['title', 'view_count', 'like_count', 'comment_count']
    if not all(col in df.columns for col in required_cols):
        missing = [col for col in required_cols if col not in df.columns]
        raise ValueError(f"DataFrame missing required columns: {missing}")

    # Sort by views and get top_n
    df_sorted = df.sort_values('view_count', ascending=False).head(top_n)

    # Create figure for views
    fig1, ax1 = plt.subplots(figsize=(12, 8))

    # Plot horizontal bar chart for views
    sns.barplot(x='view_count', y='title', data=df_sorted, ax=ax1, palette='viridis')
    ax1.set_title(f'Top {top_n} Videos by View Count')
    ax1.set_xlabel('View Count')
    ax1.set_ylabel('Video Title')

    # Format axis labels
    ax1.ticklabel_format(style='plain', axis='x')

    # Truncate long titles
    ax1.set_yticklabels([title[:50] + '...' if len(title) > 50 else title
                         for title in df_sorted['title']])

    # Create second figure for engagement
    fig2, ax2 = plt.subplots(figsize=(14, 8))

    # Calculate engagement rate (likes + comments) / views
    df_sorted['engagement_rate'] = (df_sorted['like_count'] + df_sorted['comment_count']*3) / df_sorted['view_count']

    # Sort by engagement rate
    df_sorted = df_sorted.sort_values('engagement_rate', ascending=False).head(top_n)

    # Plot engagement rate
    sns.barplot(x='engagement_rate', y='title', data=df_sorted, ax=ax2, palette='plasma')
    ax2.set_title(f'Top {top_n} Videos by Engagement Rate')
    ax2.set_xlabel('Engagement Rate ((Likes + Comments) / Views)')
    ax2.set_ylabel('Video Title')

    # Format x-axis as percentage
    ax2.set_xticklabels([f'{x:.1%}' for x in ax2.get_xticks()])

    # Truncate long titles
    ax2.set_yticklabels([title[:50] + '...' if len(title) > 50 else title
                         for title in df_sorted['title']])

    plt.tight_layout()

    logger.info(f"Created plots for top {top_n} videos by view count and engagement rate")
    return fig1, fig2

def create_word_cloud(df, text_column):

    if text_column not in df.columns:
        raise ValueError(f"Column '{text_column}' not found in DataFrame")

    # Combine all text
    text = ' '.join(df[text_column].fillna('').astype(str))

    # Create and configure the word cloud
    wordcloud = WordCloud(
        width=800,
        height=400,
        background_color='white',
        max_words=200,
        contour_width=3,
        contour_color='steelblue'
    ).generate(text)

    # Create figure and axes
    fig, ax = plt.subplots(figsize=(16, 8))

    # Plot the word cloud
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')

    if text_column == 'title':
        ax.set_title('Word Cloud of Video Titles')
    elif text_column == 'description':
        ax.set_title('Word Cloud of Video Descriptions')
    elif text_column == 'text':
        ax.set_title('Word Cloud of Comments')
    else:
        ax.set_title(f'Word Cloud of {text_column}')

    logger.info(f"Created word cloud from '{text_column}' column")
    return fig

def plot_time_distribution(df, date_column) :
    if date_column not in df.columns:
        raise ValueError(f"Column '{date_column}' not found in DataFrame")

    # Ensure the column is datetime type
    if not pd.api.types.is_datetime64_dtype(df[date_column]):
        df[date_column] = pd.to_datetime(df[date_column])

    # Create figure
    fig, ax = plt.subplots(figsize=(14, 7))

    # Resample data by month and count
    monthly_counts = df.resample('M', on=date_column).size()

    # Plot time series
    monthly_counts.plot(ax=ax, marker='o', linestyle='-', linewidth=2, markersize=8)

    # Set labels and title
    ax.set_xlabel('Date')
    ax.set_ylabel('Count')

    if date_column == 'published_at':
        if 'title' in df.columns:  # It's a video dataframe
            ax.set_title('Video Publication Over Time')
        elif 'comment_id' in df.columns:  # It's a comment dataframe
            ax.set_title('Comment Activity Over Time')
        else:
            ax.set_title('Publication Distribution Over Time')
    else:
        ax.set_title(f'Distribution of {date_column} Over Time')

    # Format x-axis ticks
    plt.xticks(rotation=45)

    # Add grid
    ax.grid(True, alpha=0.3)

    plt.tight_layout()

    logger.info(f"Created time distribution plot for '{date_column}' column")
    return fig

def plot_category_distribution(df, category_column) :

    if category_column not in df.columns:
        raise ValueError(f"Column '{category_column}' not found in DataFrame")

    # Create figure
    fig, ax = plt.subplots(figsize=(12, 8))

    # Count categories and sort
    category_counts = df[category_column].value_counts().sort_values(ascending=False)

    # Limit to top 15 categories if there are too many
    if len(category_counts) > 15:
        category_counts = category_counts.head(15)
        ax.set_title(f'Top 15 Categories by {category_column}')
    else:
        ax.set_title(f'Distribution by {category_column}')

    # Plot horizontal bar chart
    category_counts.plot(kind='barh', ax=ax, color=sns.color_palette('viridis', len(category_counts)))

    # Set labels
    ax.set_xlabel('Count')
    ax.set_ylabel(category_column)

    # Add count labels to bars
    for i, count in enumerate(category_counts):
        ax.text(count + (count * 0.01), i, f'{count}', va='center')

    plt.tight_layout()

    logger.info(f"Created category distribution plot for '{category_column}' column")
    return fig

def plot_correlation_heatmap(df, numeric_columns= None) :
    # Select numeric columns if not specified
    if numeric_columns is None:
        numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
    else:
        # Ensure all specified columns exist and are numeric
        for col in numeric_columns:
            if col not in df.columns:
                raise ValueError(f"Column '{col}' not found in DataFrame")
            if not pd.api.types.is_numeric_dtype(df[col]):
                raise ValueError(f"Column '{col}' is not numeric")

    # Calculate correlation matrix
    corr_matrix = df[numeric_columns].corr()

    # Create figure
    fig, ax = plt.subplots(figsize=(12, 10))

    # Create heatmap
    heatmap = sns.heatmap(
        corr_matrix,
        annot=True,
        cmap='coolwarm',
        fmt='.2f',
        linewidths=0.5,
        ax=ax
    )

    # Set title
    ax.set_title('Correlation Matrix of Numeric Features')

    plt.tight_layout()

    logger.info(f"Created correlation heatmap for {len(numeric_columns)} numeric columns")
    return fig

def create_interactive_scatter(df, x_col, y_col,
                               color_col= None,
                               size_col = None,
                               hover_data = None) :
    # Validate columns
    for col in [x_col, y_col]:
        if col not in df.columns:
            raise ValueError(f"Column '{col}' not found in DataFrame")

    if color_col and color_col not in df.columns:
        raise ValueError(f"Color column '{color_col}' not found in DataFrame")

    if size_col and size_col not in df.columns:
        raise ValueError(f"Size column '{size_col}' not found in DataFrame")

    if hover_data:
        for col in hover_data:
            if col not in df.columns:
                raise ValueError(f"Hover column '{col}' not found in DataFrame")

    # Create figure
    fig = px.scatter(
        df,
        x=x_col,
        y=y_col,
        color=color_col,
        size=size_col,
        hover_data=hover_data or [],
        title=f'{y_col} vs {x_col}',
        labels={
            x_col: x_col.replace('_', ' ').title(),
            y_col: y_col.replace('_', ' ').title()
        }
    )

    # Update layout
    fig.update_layout(
        template='plotly_white',
        hoverlabel=dict(bgcolor="white", font_size=12),
        width=900,
        height=600
    )

    logger.info(f"Created interactive scatter plot of {y_col} vs {x_col}")
    return fig

def create_summary_statistics(df):
    # Basic statistics for numeric columns
    numeric_stats = df.describe(include=[np.number]).T

    # Add additional statistics
    if len(numeric_stats) > 0:
        numeric_stats['range'] = numeric_stats['max'] - numeric_stats['min']
        numeric_stats['iqr'] = numeric_stats['75%'] - numeric_stats['25%']
        numeric_stats['cv'] = numeric_stats['std'] / numeric_stats['mean']  # Coefficient of variation
        numeric_stats['missing'] = df[numeric_stats.index].isna().sum()
        numeric_stats['missing_pct'] = (df[numeric_stats.index].isna().sum() / len(df)) * 100

    # For categorical columns
    categorical_columns = df.select_dtypes(include=['object']).columns

    if len(categorical_columns) > 0:
        cat_stats = pd.DataFrame({
            'type': df[categorical_columns].dtypes,
            'unique': df[categorical_columns].nunique(),
            'missing': df[categorical_columns].isna().sum(),
            'missing_pct': (df[categorical_columns].isna().sum() / len(df)) * 100
        })

        # Add most common value and its frequency
        for col in categorical_columns:
            top_value = df[col].value_counts().nlargest(1)
            if not top_value.empty:
                cat_stats.loc[col, 'top'] = top_value.index[0]
                cat_stats.loc[col, 'freq'] = top_value.iloc[0]
                cat_stats.loc[col, 'freq_pct'] = (top_value.iloc[0] / df[col].count()) * 100

        # Combine statistics
        stats = pd.concat([numeric_stats, cat_stats])
    else:
        stats = numeric_stats

    logger.info(f"Generated summary statistics for {len(df.columns)} columns")
    return stats

def detect_outliers(df,
                    numeric_columns = None,
                    method= 'iqr',
                    threshold= 1.5) :

    # Select numeric columns if not specified
    if numeric_columns is None:
        numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()

    outliers = {}

    for col in numeric_columns:
        if method == 'iqr':
            # IQR method
            q1 = df[col].quantile(0.25)
            q3 = df[col].quantile(0.75)
            iqr = q3 - q1

            lower_bound = q1 - threshold * iqr
            upper_bound = q3 + threshold * iqr

            # Identify outliers
            col_outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]

        elif method == 'zscore':
            # Z-score method
            from scipy import stats
            z_scores = stats.zscore(df[col], nan_policy='omit')

            # Identify outliers (typically |z| > 3)
            col_outliers = df[np.abs(z_scores) > threshold]

        else:
            raise ValueError(f"Unknown method: {method}. Use 'iqr' or 'zscore'.")

        # Store outliers if any found
        if len(col_outliers) > 0:
            outliers[col] = col_outliers

    logger.info(f"Detected outliers in {len(outliers)} columns using {method} method")
    return outliers


def compute_virality_score_v2(df):
    """
    Enhanced Virality Score combining multiple engagement signals.
    
    VS = (Engagement Rate × Velocity Factor × Reach Amplification) / Channel Baseline
    
    Where:
    - Engagement Rate = weighted combination of likes, comments, shares
    - Velocity Factor = views per day since publication
    - Reach Amplification = how far beyond subscriber base the video reached
    - Channel Baseline = normalizes for channel size
    """
    
    # Ensure published_at is datetime
    if not pd.api.types.is_datetime64_any_dtype(df['published_at']):
        df['published_at'] = pd.to_datetime(df['published_at'])

    # Prevent division by zero
    df['sub_count_safe'] = df['subscriber_count'].apply(lambda x: max(x, 100))
    df['duration_safe'] = df['duration_seconds'].apply(lambda x: max(x, 1))
    
    # 1. Engagement Rate (weighted by interaction depth)
    # Comments are worth more than likes (deeper engagement)
    # Note: dislike_count might be 0 if not available
    dislike = df['dislike_count'] if 'dislike_count' in df.columns else 0
    
    df['engagement_rate'] = (
        (df['like_count'] * 1.0 + 
         df['comment_count'] * 3.0 + 
         dislike * 0.5) / df['view_count'].apply(lambda x: max(x, 1))
    )
    
    # 2. Velocity Factor (views per day)
    df['days_since_publish'] = (pd.Timestamp.now() - df['published_at']).dt.total_seconds() / 86400
    df['days_since_publish'] = df['days_since_publish'].apply(lambda x: max(x, 1))
    df['velocity'] = df['view_count'] / df['days_since_publish']
    
    # 3. Reach Amplification (how far beyond subscriber base)
    df['reach_ratio'] = df['view_count'] / df['sub_count_safe']
    
    # 4. Retention Quality (engagement per minute of content)
    df['engagement_density'] = (
        (df['like_count'] + df['comment_count']) / 
        (df['duration_safe'] / 60)  # per minute of video
    )
    
    # 5. Combined Virality Score
    df['virality_score'] = (
        df['engagement_rate'] * 0.25 +
        np.log1p(df['velocity']) * 0.30 +
        np.log1p(df['reach_ratio']) * 0.30 +
        np.log1p(df['engagement_density']) * 0.15
    )
    
    # Normalize to 0-100 scale
    # Check if max != min to avoid division by zero
    min_score = df['virality_score'].min()
    max_score = df['virality_score'].max()
    
    if max_score != min_score:
        df['virality_score'] = (
            (df['virality_score'] - min_score) / 
            (max_score - min_score) * 100
        )
    else:
        df['virality_score'] = 0
    
    # Binary label: Top 10% are viral
    threshold = df['virality_score'].quantile(0.9)
    df['is_viral_label'] = (df['virality_score'] >= threshold).astype(int)
    
    logger.info("Computed virality score v2 and added 'is_viral_label' column")
    return df
